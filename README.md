### 方法
#### A. 整体架构
我们提出的InconSeg的整体架构如图2所示。有两个数据流：深度/视差流和RGB流。深度/视差流以深度或视差图像作为输入。由于深度和视差图像可以容易地相互转换，因此以下文本中我们使用“深度”而不是“深度/视差”以方便起见。每个流都有一个5级编码器和一个5级解码器。RGB流的输出 $\hat{y}_ {rgb}$ 是网络InconSeg的输出。在编码器中，每个阶段将输入图像的分辨率减半。在解码器中，每个阶段将分辨率翻倍，并将特征图的通道数减半。深度流的输出 $\hat{y}_ {d}$ 仅在训练期间使用。编码器借鉴自ResNet-152。

在每个流中，编码器的每个阶段的输入与解码器的同一级别的输出通过逐元素加法融合。与现有的网络（例如MAFNet和AA-RTFNet）不同，我们在同一级别的解码器的输出融合，以避免由编码器提取的特征图的不一致性引起的负面影响。深度解码器的最后两个阶段的输出通过逐元素加法融合到RGB解码器的同一级别的阶段。深度流解码器的前三个阶段的输出通过我们提出的残差引导融合（Residual-Guided Fusion，RGF）模块与RGB解码器的同一级别的输出融合。三个RGF模块放置在RGB解码器中。第n个RGF模块放置在RGB解码器的第n个阶段之后，其中n ∈ [1, 2, 3]。

#### B. RGF模块
如上所述，RGF模块的目的是量化RGB特征和地面真实情况之间的缺失特征。RGF模块从深度特征中提取RGB特征的补充特征，而不是直接融合它们，从而解决由不一致数据引起的融合性能下降的问题。我们的RGF模块的结构如图2右下角所示。该模块有两个输入：RGB特征图和深度特征图。

首先，RGF模块生成RGB模态的缺失特征。具体来说，RGB特征图通过1×1卷积层生成RGB预测掩码$\hat{y}_{n}$，其中n表示第n个RGF模块。需要注意的是，第一个RGF模块不包含1×1卷积。残差掩码$y_{n}^{res}$是通过$\hat{y}_{n}$和地面真实情况$y_{n}$之间的逐元素减法生成的。残差掩码$y_{n}^{res}$代表残差特征。我们称$y_{n}^{res}$为RGB特征图的缺失特征。$\hat{y}_{n}$和$y_{n}$与RGB特征图具有相同的分辨率。$y_{n}$是从原始地面真实情况y使用最近邻方法进行下采样生成的。

其次，我们为缺失特征提取补充特征。具体来说，我们通过逐元素减法将RGB特征图与深度特征图相减，得到它们之间的差异。不同特征的通道通过1×1卷积调整到类别数。需要注意的是，第一个RGF模块不包含1×1卷积。然后，使用具有3×3卷积的残差单元生成预测残差掩码$\hat{y}_{n}^{res}$。$y_{n}^{res}$用于引导$\hat{y}_{n}^{res}$的生成。$\hat{y}_{n}^{res}$的通道通过1×1卷积调整为RGB特征图的通道数。之后，调整后的结果通过逐元素乘法与RGB特征图融合。最后，调整后的结果、融合结果和RGB特征图沿通道维度进行连接。RGF模块的输出通过1×1卷积生成，该输出输入到RGB解码器的下一阶段。

#### C. 解码器的结构
每个解码器阶段的结构如图3所示。首先，输入特征图输入到双分支残差结构中。残差结构将输入特征图的分辨率减半。上分支有一个1×1卷积-批量归一化（BN）-ReLU层。下分支有三个3×3卷积-BN-ReLU层。下分支的第一层将输入特征图的分辨率减半。下分支的其他层保持通道数不变。两个分支的输出通过逐元素加法融合。

#### D. 损失函数
为了从深度特征图中提取RGB特征图的残差特征以进行语义分割，深度流需要独立实现语义分割的能力。因此，在训练过程中，还需要计算地面真实情况y和深度流输出$\hat{y}_{d}$之间的损失。我们计算地面真实情况y和深度流输出$\hat{y}_{d}$之间的交叉熵损失$L_{seg}(y, \hat{y}_{d})$，以及地面真实情况y和RGB流输出$\hat{y}_{rgb}$之间的交叉熵损失$L_{seg}(y, \hat{y}_{rgb})$，以训练InconSeg。

在第n个RGF模块中，我们使用地面真实情况$y_{n}$和RGB预测掩码$\hat{y}_{n}$之间的交叉熵损失$L_{seg}(y_{n}, \hat{y}_{n})$来引导RGB残差特征$y_{n}^{res}$的生成。

我们还使用RGB残差特征$y_{n}^{res}$和预测残差特征$\hat{y}_{n}^{res}$之间的交叉熵损失$L_{seg}(y_{n}^{res}, \hat{y}_{n}^{res})$来引导从深度特征图中提取RGB残差特征。因此，第n个RGF模块的损失$L_{n RGF}$表示为：$L_{n RGF} = L_{seg}(y_{n}, \hat{y}_{n}) + L_{seg}(y_{n}^{res}, \hat{y}_{n}^{res})$。每个RGF模块的损失也用于训练我们的InconSeg。总结来说，总损失$L_{total}$计算为：$L_{total} = L_{seg}(y, \hat{y}_{d}) + L_{seg}(y, \hat{y}_{rgb}) + \sum_{n=1}^{3} L_{n RGF}$。我们使用$L_{total}$来训练我们的InconSeg。
